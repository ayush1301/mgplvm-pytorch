{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.special import gamma, kv\n",
    "from numpy import matlib\n",
    "\n",
    "import torch\n",
    "import mgplvm as mgp\n",
    "import pickle\n",
    "import time\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from scipy.interpolate import CubicSpline\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['axes.spines.right'] = False\n",
    "plt.rcParams['axes.spines.top'] = False\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "device = mgp.utils.get_device() # use GPU if available, otherwise CPU\n",
    "print(device)\n",
    "\n",
    "from scipy.stats import poisson\n",
    "from synthetic_data import *\n",
    "\n",
    "import sys\n",
    "import io\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mod = pickle.load(open('models/50k_kernel_0_seed_0model.pickled', 'rb'))\n",
    "mod = pickle.load(open('models/50k_r1_kernel_0_seed_0model.pickled', 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 200, 70482)\n"
     ]
    }
   ],
   "source": [
    "data = pickle.load(open('data/Doherty_example.pickled', 'rb')) # load example data\n",
    "binsize = 25 # binsize in ms\n",
    "timepoints = np.arange(0, 50000) #subsample ~40 seconds of data so things will run somewhat quicker\n",
    "print(data['Y'].shape)\n",
    "fit_data = {'Y': data['Y'][..., timepoints], 'locs': data['locs'][timepoints, :], 'targets': data['targets'][timepoints, :], 'binsize': binsize}\n",
    "# fit_data = {'Y': data['Y'], 'locs': data['locs'], 'targets': data['targets'], 'binsize': binsize}\n",
    "Y = fit_data['Y'] # these are the actual recordings and is the input to our model\n",
    "targets = fit_data['targets'] # these are the target locations\n",
    "locs = fit_data['locs'] # these are the hand positions\n",
    "# print(Y.shape)\n",
    "Y = Y[:, np.mean(Y,axis = (0, 2))/0.025 > 2, :] #subsample highly active neurons so things will run a bit quicker\n",
    "# print(Y.shape)\n",
    "ntrials, n, T = Y.shape # Y should have shape: [number of trials (here 1) x neurons x time points]\n",
    "data = torch.tensor(Y).to(device) # put the data on our GPU/CPU\n",
    "ts = np.arange(Y.shape[-1]) #much easier to work in units of time bins here\n",
    "fit_ts = torch.tensor(ts)[None, None, :].to(device) # put our time points on GPU/CPU\n",
    "\n",
    "# finally let's just identify bins where the target changes\n",
    "deltas = np.concatenate([np.zeros(1), np.sum(np.abs(targets[1:, :] - targets[:-1, :]), axis = 1)])\n",
    "switches = np.where(deltas > 1e-5)[0] # change occurs during time bin s\n",
    "dswitches = np.concatenate([np.ones(1)*10, switches[1:] - switches[:-1]]) # when the target changes during a bin there will be two discontinuities\n",
    "inds = np.zeros(len(switches)).astype(bool)\n",
    "inds[dswitches > 1.5] = 1 # index of the bin where the target changes or the first bin with a new target\n",
    "switches = switches[inds]\n",
    "\n",
    "# print(np.mean(Y, axis = (0, 2)))\n",
    "\n",
    "### set some parameters for fitting ###\n",
    "ell0 = 200/binsize # initial timescale (in bins) for each dimension. This could be the ~timescale of the behavior of interest (otherwise a few hundred ms is a reasonable default)\n",
    "rho = 2 # sets the intial scale of each latent (s_d in Jensen & Kao). rho=1 is a natural choice with Gaussian noise; less obvious with non-Gaussian noise but rho=1-5 works well empirically.\n",
    "max_steps = 1001 # number of training iterations\n",
    "# n_mc = 5 # number of monte carlo samples per iteration\n",
    "print_every = 100 # how often we print training progress\n",
    "d_fit = 20 # lets fit up to 1\n",
    "\n",
    "\n",
    "### construct the actual model ###\n",
    "ntrials, n, T = Y.shape # Y should have shape: [number of trials (here 1) x neurons x time points]\n",
    "\n",
    "ts = np.arange(Y.shape[-1])*fit_data['binsize'] # measured in ms\n",
    "cs = CubicSpline(ts, locs) # fit cubic spline to behavior\n",
    "vels = cs(ts, 1) # velocity (first derivative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running decoding analysis\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "### finally let's do a simple decoding analysis ###\n",
    "torch.cuda.empty_cache() # clear GPU memory\n",
    "print('running decoding analysis')\n",
    "Ypreds = [] # decode from the inferred firing rates (this is a non-linear decoder from latents)\n",
    "query = mod.lat_dist.lat_mu.detach().transpose(-1, -2).to(device)  # (ntrial, d_fit, T)\n",
    "for i in range(100): # loop over mc samples to avoid memory issues\n",
    "    Ypred = mod.svgp.sample(query, n_mc=10, noise=False) # OG n_mc = 100\n",
    "    Ypred = Ypred.detach().mean(0).cpu().numpy()  # (ntrial x n x T)\n",
    "    Ypreds.append(Ypred)\n",
    "Ypred = np.mean(np.array(Ypreds), axis = (0,1)).T # T x n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5000  5001  5002 ... 49997 49998 49999] [   0    1    2 ... 4997 4998 4999]\n",
      "[    0     1     2 ... 49997 49998 49999] [5000 5001 5002 ... 9997 9998 9999]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0     1     2 ... 49997 49998 49999] [10000 10001 10002 ... 14997 14998 14999]\n",
      "[    0     1     2 ... 49997 49998 49999] [15000 15001 15002 ... 19997 19998 19999]\n",
      "[    0     1     2 ... 49997 49998 49999] [20000 20001 20002 ... 24997 24998 24999]\n",
      "[    0     1     2 ... 49997 49998 49999] [25000 25001 25002 ... 29997 29998 29999]\n",
      "[    0     1     2 ... 49997 49998 49999] [30000 30001 30002 ... 34997 34998 34999]\n",
      "[    0     1     2 ... 49997 49998 49999] [35000 35001 35002 ... 39997 39998 39999]\n",
      "[    0     1     2 ... 49997 49998 49999] [40000 40001 40002 ... 44997 44998 44999]\n",
      "[    0     1     2 ... 44997 44998 44999] [45000 45001 45002 ... 49997 49998 49999]\n",
      "plotting decoding\n",
      "0.7399021437201105\n",
      "0.025524792760091213\n"
     ]
    }
   ],
   "source": [
    "# delays = np.linspace(0, 250, 100) # consider different behavioral delays\n",
    "# performance = np.zeros((len(delays), 2)) # model performance\n",
    "# for idelay, delay in enumerate(delays):\n",
    "#     vels = cs(ts+delay, 1) # velocity at time+delay\n",
    "#     for itest, Ytest in enumerate([Ypred]): # bGPFA\n",
    "#         regs = [Ridge(alpha=1e-3).fit(Ytest[::2, :], vels[::2, i]) for i in range(2)] # fit x and y vel on half the data\n",
    "#         scores = [regs[i].score(Ytest[1::2, :], vels[1::2, i]) for i in range(2)] # score x and y vel on the other half\n",
    "#         # regs = [Ridge(alpha=1e-3).fit(Ytest[2400:, :], vels[2400:, i]) for i in range(2)] # fit x and y vel on half the data\n",
    "#         # scores = [regs[i].score(Ytest[:2400, :], vels[:2400, i]) for i in range(2)] # score x and y vel on the other half\n",
    "#         # regs = [Ridge(alpha=1e-3).fit(Ytest, vels[:, i]) for i in range(2)]\n",
    "#         # scores = [regs[i].score(Ytest, vels[:, i]) for i in range(2)]\n",
    "#         performance[idelay, itest] = np.mean(scores) # save performance\n",
    "# print('plotting decoding')\n",
    "# plt.figure()\n",
    "# plt.plot(delays, performance[:, 0], 'k-')\n",
    "# print(max(performance[:, 0]))\n",
    "# plt.axvline(delays[np.argmax(performance[:, 0])], color = 'b', ls = '--')\n",
    "# plt.xlim(delays[0], delays[-1])\n",
    "# plt.xlabel('delay (ms)')\n",
    "# plt.ylabel('kinematic decoding')\n",
    "# plt.show()\n",
    "\n",
    "folds = 10\n",
    "delay = 100\n",
    "performance = np.zeros(folds)\n",
    "for fold in range(folds):\n",
    "    # train, test = train_test_split(np.arange(Y.shape[-1]), test_size=0.1, random_state=fold)\n",
    "    test_size = int(Y.shape[-1] / folds)\n",
    "    test_start = fold * test_size\n",
    "    test_end = test_start + test_size\n",
    "    test = np.arange(test_start, test_end)\n",
    "    train = np.concatenate([np.arange(0, test_start), np.arange(test_end, Y.shape[-1])])\n",
    "    print(train , test)\n",
    "# delays = np.linspace(0, 250, 100) # consider different behavioral delays\n",
    "# performance = np.zeros((len(delays), 2)) # model performance\n",
    "# for idelay, delay in enumerate(delays):\n",
    "    vels = cs(ts+delay, 1) # velocity at time+delay\n",
    "    for itest, Ytest in enumerate([Ypred]): # bGPFA\n",
    "        regs = [Ridge(alpha=1e-3).fit(Ytest[train], vels[train]) for i in range(2)] # fit x and y vel on half the data\n",
    "        scores = [regs[i].score(Ytest[test], vels[test]) for i in range(2)] # score x and y vel on the other half\n",
    "        # regs = [Ridge(alpha=1e-3).fit(Ytest[2400:, :], vels[2400:, i]) for i in range(2)] # fit x and y vel on half the data\n",
    "        # scores = [regs[i].score(Ytest[:2400, :], vels[:2400, i]) for i in range(2)] # score x and y vel on the other half\n",
    "        # regs = [Ridge(alpha=1e-3).fit(Ytest, vels[:, i]) for i in range(2)]\n",
    "        # scores = [regs[i].score(Ytest, vels[:, i]) for i in range(2)]\n",
    "        performance[fold] = np.mean(scores) # save performance\n",
    "print('plotting decoding')\n",
    "print(np.mean(performance))\n",
    "print(np.std(performance))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
